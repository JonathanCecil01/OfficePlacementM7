from office import *
from tags import *
from preprocessing import preprocess
import matplotlib.pyplot as plt
import csv
from nn_keras import *
import json


colors = ["red", "blue", "brown", "black", "purple", "yellow", "pink", "orange"]

def write_results(products, landmarks):
    result_dict = {}
    for landmark in landmarks:
        result_dict[landmark.id] = {}

    for product in products:
        if product.predicted_landmark_id == None:
            continue
        if product.id in result_dict[product.predicted_landmark_id]:
            result_dict[product.predicted_landmark_id][product.id].append(product.item_no)
        else:
            result_dict[product.predicted_landmark_id][product.id] = [product.item_no]
    
    
    json_string = json.dumps(result_dict, indent = 2)
    with open("results.json", "w") as f:
        f.write(json_string)


def write_data(passive_landmarks, landmarks, products, reader): #writing data for data genertion by NN_training_testing.ipynb
    active_landmark_list = []
    for landmark in landmarks:
        for i in range(0, len(landmark.timestamp)):
            active_landmark_list.append([landmark.id, 0, landmark.item_no, landmark.rssi[i], landmark.max_rssi, landmark.rssi_A, 1,reader.queue, reader.rxpower, reader.session,landmark.start_timestamp, landmark.timestamp[i], True, 0])
    product_list = []
    for product in products:
        for i  in range(len(product.rssi)):
            product_list.append([0, product.id, product.item_no, product.rssi[i], product.max_rssi, product.rssi_A, 1,reader.queue, reader.rxpower, reader.session, product.start_timestamp, product.timestamp[i], False, product.actual_landmark_id])

    landmark_list = []
    for landmark in passive_landmarks:
        for i in range(0, len(landmark.timestamp)):
            landmark_list.append([landmark.id, 0,  landmark.item_no, landmark.rssi[i], landmark.max_rssi, landmark.rssi_A, 1,reader.queue, reader.rxpower, reader.session,landmark.start_timestamp, landmark.timestamp[i], True, 0])
            
    with open('OfficeSpaceUtil/rawData.csv', 'w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["locationId","productId", 'EPC', 'rssi', 'minrssi', 'maxrssi', 'count', 'queue', 'rxpower','session', 'starttimestamp', 'endtimestamp','isLocation', 'expectedLocation'])
        writer.writerows(product_list)
        writer.writerows(active_landmark_list)
        writer.writerows(landmark_list)


if __name__ == '__main__':
    reader = Reader([0, 0], 0, 30, 4)
    office = Office(reader)
    result = office.animation() #draw animation for data generation
    color_dict = {}
    for landmark in office.active_landmarks: #hash map for colours and location
        color_dict[landmark.id] = landmark.color
    #calculatigm the rssi value for all tags to use for prediction
    office.calculate_rssi()
    #writing the data for each landmark and product
    write_data(office.passive_landmarks, office.active_landmarks, office.products, office.reader)
    preprocess()
    #prediction with the loaded NN generated by NN_training_testing.ipynb
    office.predicted_products = run_model(office.products, color_dict)
    office.result_renderer() #render the results to a new animation window for visualization of the classification results
    write_results(office.predicted_products, office.active_landmarks)
