{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRBghSyNvcFu"
      },
      "source": [
        "Installing the Necessary libraried from HayStack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQ4Iwf5Mfbhl"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "pip install --upgrade pip\n",
        "pip install farm-haystack[colab,faiss,inference,ocr,preprocessing,file-conversion,pdf]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y16ANSKMvqe8"
      },
      "source": [
        "Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQWEUUMnzqLX",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kelekZhevsaD"
      },
      "source": [
        "Creating a Document store for the required pdfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cYgDJmrA6Nv",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from haystack.document_stores import FAISSDocumentStore\n",
        "\n",
        "document_store = FAISSDocumentStore(faiss_index_factory_str=\"Flat\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1G-ev1Ev1-O"
      },
      "source": [
        "Preprocessing the Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UiN8Uq4gRn9"
      },
      "outputs": [],
      "source": [
        "from haystack.utils import clean_wiki_text, convert_files_to_docs, fetch_archive_from_http\n",
        "from haystack.nodes import PreProcessor\n",
        "\n",
        "doc_dir = \"ContextSearching/hayStack_implementation/data\"\n",
        "\n",
        "docs = convert_files_to_docs(dir_path=doc_dir, clean_func=clean_wiki_text, split_paragraphs=True)\n",
        "preprocessor = PreProcessor(\n",
        "    clean_empty_lines=True,\n",
        "    clean_whitespace=True,\n",
        "    clean_header_footer=False,\n",
        "    split_by=\"word\",\n",
        "    split_length=100,\n",
        "    split_respect_sentence_boundary=True,\n",
        ")\n",
        "preprocessed_docs = preprocessor.process(docs)\n",
        "print(f\"n_docs_input: 1\\nn_docs_output: {len(preprocessed_docs)}\")\n",
        "# Now, let's write the dicts containing documents to our DB.\n",
        "document_store.write_documents(preprocessed_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKxq1S_0v3vX"
      },
      "source": [
        "Initializing the Embedding Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2zCc_WgTjZK-"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'haystack'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhaystack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnodes\u001b[39;00m \u001b[39mimport\u001b[39;00m EmbeddingRetriever\n\u001b[1;32m      3\u001b[0m retriever \u001b[39m=\u001b[39m EmbeddingRetriever(\n\u001b[1;32m      4\u001b[0m     document_store\u001b[39m=\u001b[39mdocument_store, embedding_model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msentence-transformers/multi-qa-mpnet-base-dot-v1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m document_store\u001b[39m.\u001b[39mupdate_embeddings(retriever)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'haystack'"
          ]
        }
      ],
      "source": [
        "from haystack.nodes import EmbeddingRetriever\n",
        "\n",
        "retriever = EmbeddingRetriever(\n",
        "    document_store=document_store, embedding_model=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
        ")\n",
        "\n",
        "document_store.update_embeddings(retriever)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOJnMqANv_CP"
      },
      "source": [
        "Initializing the Reader, it uses Roberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyIuWVwhA6OB"
      },
      "outputs": [],
      "source": [
        "from haystack.nodes import FARMReader\n",
        "\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3GLgIImwEu5"
      },
      "source": [
        "Creating the Pipeline for Reader and Retriver Nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ussr764kjqVp"
      },
      "outputs": [],
      "source": [
        "from haystack.pipelines import ExtractiveQAPipeline\n",
        "\n",
        "pipe = ExtractiveQAPipeline(reader, retriever)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZEyv0HOwLgA"
      },
      "source": [
        "Sample Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g52UqQBVjrOh"
      },
      "outputs": [],
      "source": [
        "from haystack.utils import print_answers\n",
        "\n",
        "prediction = pipe.run(\n",
        "    query=\"How much is the Main Fund?\", params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
        ")\n",
        "print(prediction['answers'][0].meta['name'])\n",
        "print_answers(prediction, details=\"minimum\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvjVwIjpwPD0"
      },
      "source": [
        "Runnning all Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zv1e0IInlQ9"
      },
      "outputs": [],
      "source": [
        "queries = [\"what is the Fund Name?\", \"When is the Start Date?\", \"Which Section has Carried Interest?\", \"Who is the General Partner?\", \"Which secition is about Initial Closing Date?\", \"When is the Final Closing Date?\", \"Which is the Management Company?\", \"What are the Investment Limitations?\", \"What is the Purpose?\", \"How long is the Partnership Term?\", \"How much is the Main Fund?\", \"How Much is the Transaction Fees?\", \"How much is the Makeup Contribution?\"]\n",
        "predictions = {}\n",
        "for query in queries:\n",
        "    prediction = pipe.run( query, params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}})\n",
        "    predictions[query] = []\n",
        "    for i in prediction['answers']:\n",
        "      temp_dict = {}\n",
        "      temp_dict['answer'] = i.answer\n",
        "      temp_dict['context'] = i.context\n",
        "      temp_dict['filename'] = i.meta['name']\n",
        "      temp_dict['score'] = i.score\n",
        "\n",
        "      predictions[query].append(temp_dict)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUJPHSOrwRLH"
      },
      "source": [
        "Writing a Json File of the Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "leBbJANKnn9J"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "json_string = json.dumps(predictions, indent = 2)\n",
        "with open(\"context_search_results.json\", \"w\") as f:\n",
        "  f.write(json_string)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
