# -*- coding: utf-8 -*-
"""ROP_Image_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oJVDKb6sxzsSZbayQsWcBoBV4qnQ7Mp3
"""

import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.python.keras.layers import Dense, Flatten
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.layers import Flatten, Activation, Dropout, Dense, Conv2D, MaxPooling2D
from tensorflow.keras.models import Model

import pandas as pd
from sklearn.model_selection import train_test_split
from shutil import copyfile
import ssl
ssl._create_default_https_context = ssl._create_unverified_context

img_height,img_width=180,180
EPOCHS = 50

classes   = ['Stage_0', 'Stage_1', 'Stage_2', 'Stage_3']

def create_classes_dirctory(path):
  path_to_images = path
  stage1_folder = 'Stage_1'
  stage2_folder = 'Stage_2'
  stage0_folder = 'Stage_0'
  stage3_folder = 'Stage_3'

  stage1 = []
  stage2 = []
  stage3 = []
  no_rop = []
  for image in os.listdir(path_to_images):
    if 'NoROP' in image:
      no_rop.append(image)
    elif 'Stage1' in image:
      stage1.append(image)
    elif 'Stage2' in image:
      stage2.append(image)
    elif 'Stage3' in image:
      stage3.append(image)

  stage0_path = os.path.join(path_to_images, stage0_folder)
  stage1_path = os.path.join(path_to_images, stage1_folder)
  stage2_path = os.path.join(path_to_images, stage2_folder)
  stage3_path = os.path.join(path_to_images, stage3_folder)

  os.makedirs(stage0_path, exist_ok = True)
  os.makedirs(stage1_path, exist_ok = True)
  os.makedirs(stage2_path, exist_ok = True)
  os.makedirs(stage3_path, exist_ok = True)

  for image in stage1:
    src_path = os.path.join(path_to_images, image)
    dest_path = os.path.join(stage1_path, image)
    copyfile(src_path, dest_path)
    os.remove(src_path)

  for image in no_rop:
    src_path = os.path.join(path_to_images, image)
    dest_path = os.path.join(stage0_path, image)
    copyfile(src_path, dest_path)
    os.remove(src_path)

  for image in stage2:
    src_path = os.path.join(path_to_images, image)
    dest_path = os.path.join(stage2_path, image)
    copyfile(src_path, dest_path)
    os.remove(src_path)

  for image in stage3:
    src_path = os.path.join(path_to_images, image)
    dest_path = os.path.join(stage3_path, image)
    copyfile(src_path, dest_path)
    os.remove(src_path)
  
  return

def load_preprocess_images(path_to_images):
  batch_size=32
  train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    path_to_images,
    validation_split=0.1,
    subset="training",
    seed=123,
    image_size=(img_height, img_width),
    batch_size=batch_size)

    # Separate images and labels from the training dataset
  train_images = []
  train_labels = []

  for images, labels in train_ds:
      train_images.append(images)
      train_labels.append(labels)

  train_images = tf.concat(train_images, axis=0)
  train_labels = tf.concat(train_labels, axis=0)

  # Manually one-hot encode the training labels
  train_labels_one_hot = to_categorical(train_labels.numpy(), num_classes=4)


  val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    path_to_images,
    validation_split=0.1,
    subset="validation",
    seed=123,
    image_size=(img_height, img_width),
    batch_size=batch_size)

  val_images = []
  val_labels = []

  for images, labels in val_ds:
      val_images.append(images)
      val_labels.append(labels)

  val_images = tf.concat(val_images, axis=0)
  val_labels = tf.concat(val_labels, axis=0)

  # Manually one-hot encode the validation labels
  val_labels_one_hot = to_categorical(val_labels.numpy(), num_classes=4)

  class_names = train_ds.class_names
  print("The classes are: ", class_names)

  return (train_images, train_labels_one_hot, val_images, val_labels_one_hot, train_ds, val_ds, class_names)



def plot_images(train_ds):
  class_names = train_ds.class_names
  plt.figure(figsize=(10, 10))
  for images, labels in train_ds.take(1):
    for i in range(6):
      ax = plt.subplot(3, 3, i + 1)
      plt.imshow(images[i].numpy().astype("uint8"))
      plt.title(class_names[labels[i]])
      plt.axis("off")
  plt.show()

def build_cnn_model():
   model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3)),
    MaxPooling2D(2, 2),
    
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    
    Flatten(),
    
    Dense(512, activation='relu'),
    Dropout(0.2),  # Add dropout to reduce overfitting
    
    Dense(4, activation='sigmoid')  # Output layer with sigmoid activation for binary classification
    # Change the output layer activation and units for multi-class classification
   ])
   model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
   return model


def build_inceptionV3_model():
  rop_classifier = Sequential()
  pretrained_model = InceptionV3( input_shape=(img_height,img_width,3),classes=4,
                    weights='imagenet', include_top = False)
  for layer in pretrained_model.layers:
          layer.trainable=False
  rop_classifier.add(pretrained_model)
  rop_classifier.add(Flatten())
  rop_classifier.add(Activation('relu'))
  rop_classifier.add(Dropout(0.2))
  rop_classifier.add(Dense(1024, activation = 'relu'))
  rop_classifier.add(Dropout(0.2))
  rop_classifier.add(Dense(540, activation = 'relu'))
  rop_classifier.add(Dropout(0.2))
  rop_classifier.add(Dense(4, activation = 'softmax'))
  rop_classifier.summary()

  rop_classifier.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])
  rop_classifier.summary()
  return rop_classifier

def train_model(rop_classifier, train_images ,train_labels_one_hot, val_images, val_labels_one_hot):
  history = rop_classifier.fit(train_images, train_labels_one_hot,
                              validation_data =(val_images, val_labels_one_hot),
                              epochs = EPOCHS, batch_size = 20)
  return history

def plot_loss_gain(history):
  fig1 = plt.gcf()
  plt.plot(history.history['accuracy'])
  plt.plot(history.history['val_accuracy'])
  plt.axis(ymin=0.4,ymax=1)
  plt.grid()
  plt.title('Model Accuracy')
  plt.ylabel('Accuracy')
  plt.xlabel('Epochs')
  plt.legend(['train', 'validation'])
  plt.show()

  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  plt.grid()
  plt.title('Model Loss')
  plt.ylabel('Loss')
  plt.xlabel('Epochs')
  plt.legend(['train', 'validation'])
  plt.show()
  return


def predict(classifier, image_path, class_names):
   import cv2
   image=cv2.imread(image_path)
   image_resized= cv2.resize(image, (img_height,img_width))
   image=np.expand_dims(image_resized,axis=0)
   pred=classifier.predict(image)
   print(pred)

   output_class=class_names[np.argmax(pred)]
   print("The predicted class is", output_class)




if __name__ == '__main__':
   
   '''Uncomment the following lines to train the model with the images in ROP_images folder and save the model'''
   path_to_images = "ROP_images"
   create_classes_dirctory(path_to_images)
   train_val_set = load_preprocess_images(path_to_images)
   train_images = train_val_set[0]
   train_labels = train_val_set[1]
   val_images = train_val_set[2]
   val_labels = train_val_set[3]
   classes = train_val_set[-1]
   classifier = build_inceptionV3_model()
  #  classifier.save("Modified_InceptionV3")
   history = train_model(rop_classifier=classifier,train_images=train_images, train_labels_one_hot= train_labels, val_images=val_images, val_labels_one_hot=val_labels)
  #  classifier = tf.keras.models.load_model("CNN_classifier")
   predict(classifier, "prediction_image.jpeg", classes)